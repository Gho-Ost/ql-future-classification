{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Y-net Model"
      ],
      "metadata": {
        "id": "dv24-zWQGhsY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notebook for classification and segmentation mixed model"
      ],
      "metadata": {
        "id": "A5f3MMvQGjnl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installs and Imports"
      ],
      "metadata": {
        "id": "lxM2o5QLGqDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import cv2\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import AdamW, Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
        "import pickle"
      ],
      "metadata": {
        "id": "Zj66pcgAHEae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utilities"
      ],
      "metadata": {
        "id": "6W7UWegeHugT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_data(directory, target_size = (300, 300)):\n",
        "    all_files = os.listdir(directory)\n",
        "    not_mask_images = sorted([file for file in all_files if \"mask\" not in file])\n",
        "    mask_images = sorted([file for file in all_files if \"mask\" in file])\n",
        "    images = []\n",
        "    masks = []\n",
        "    temp_masks = []\n",
        "\n",
        "    for file_name in not_mask_images:\n",
        "        image = cv2.imread(os.path.join(directory, file_name))\n",
        "        images.append(cv2.resize(image, target_size))\n",
        "\n",
        "    prev_file = None\n",
        "    for file_name in mask_images:\n",
        "        image = cv2.imread(os.path.join(directory, file_name), cv2.IMREAD_GRAYSCALE)\n",
        "        image = cv2.resize(image, target_size)\n",
        "        if prev_file != None and (str(prev_file).replace(\".png\", \"\").replace(\" \", \"_\") in str(file_name).replace(\".png\", \"\").replace(\" \",\"_\")):\n",
        "            masks[-1] += image\n",
        "        else:\n",
        "            temp_masks.append(file_name)\n",
        "            masks.append(image)\n",
        "            prev_file = file_name\n",
        "\n",
        "    return np.array(images), np.array(masks)\n",
        "\n",
        "def show_image(data, index):\n",
        "    image = data[index]\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "0goayF59GeWV"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model definition"
      ],
      "metadata": {
        "id": "fwMXlnn5H1q3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self, base_model):\n",
        "        super(UNet, self).__init__()\n",
        "        self.model = base_model\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=3)\n",
        "        self.fc1 = nn.Linear(28900, 512)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.output = nn.Linear(128, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        segmented = self.model(x)\n",
        "        concatenated = torch.cat((x, segmented), dim=1)\n",
        "        classified = self.maxpool(concatenated)\n",
        "        classified = classified.view(classified.size(0), -1)\n",
        "        classified = self.fc1(classified)\n",
        "        classified = self.relu1(classified)\n",
        "        classified = self.fc2(classified)\n",
        "        classified = self.relu2(classified)\n",
        "        classified = self.fc3(classified)\n",
        "        classified = self.relu3(classified)\n",
        "        output = self.output(classified)\n",
        "        return segmented, output"
      ],
      "metadata": {
        "id": "ZmVQSbTqHRek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Parts of the U-Net model \"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class DoubleConv(nn.Module):\n",
        "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
        "        super().__init__()\n",
        "        if not mid_channels:\n",
        "            mid_channels = out_channels\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(mid_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "\n",
        "class Down(nn.Module):\n",
        "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.maxpool_conv = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            DoubleConv(in_channels, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.maxpool_conv(x)\n",
        "\n",
        "\n",
        "class Up(nn.Module):\n",
        "    \"\"\"Upscaling then double conv\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
        "        super().__init__()\n",
        "\n",
        "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
        "        if bilinear:\n",
        "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
        "        else:\n",
        "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
        "            self.conv = DoubleConv(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        # input is CHW\n",
        "        diffY = x2.size()[2] - x1.size()[2]\n",
        "        diffX = x2.size()[3] - x1.size()[3]\n",
        "\n",
        "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
        "                        diffY // 2, diffY - diffY // 2])\n",
        "        # if you have padding issues, see\n",
        "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
        "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class OutConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(OutConv, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n"
      ],
      "metadata": {
        "id": "P2_XFdw2HVxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes, bilinear=False):\n",
        "        super(UNet, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.bilinear = bilinear\n",
        "\n",
        "        self.inc = (DoubleConv(n_channels, 64))\n",
        "        self.down1 = (Down(64, 128))\n",
        "        self.down2 = (Down(128, 256))\n",
        "        self.down3 = (Down(256, 512))\n",
        "        factor = 2 if bilinear else 1\n",
        "        self.down4 = (Down(512, 1024 // factor))\n",
        "        self.up1 = (Up(1024, 512 // factor, bilinear))\n",
        "        self.up2 = (Up(512, 256 // factor, bilinear))\n",
        "        self.up3 = (Up(256, 128 // factor, bilinear))\n",
        "        self.up4 = (Up(128, 64, bilinear))\n",
        "        self.outc = (OutConv(64, n_classes))\n",
        "        self.simoid = nn.Sigmoid()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1024, 512, kernel_size=3)\n",
        "        self.conv2 = nn.Conv2d(512, 256, kernel_size=3)\n",
        "        self.conv3 = nn.Conv2d(256, 128, kernel_size=3)\n",
        "        self.max_pool = nn.MaxPool2d(3)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear1 = nn.Linear(1152, 256)\n",
        "        self.linear2 = nn.Linear(256, 64)\n",
        "        self.linear3 = nn.Linear(64, 16)\n",
        "        self.linear4 = nn.Linear(16, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        logits = self.outc(x)\n",
        "        logits = self.simoid(logits)\n",
        "\n",
        "        x_class = self.conv1(x5)\n",
        "        x_class = self.conv2(x_class)\n",
        "        x_class = self.conv3(x_class)\n",
        "        x_class = self.max_pool(x_class)\n",
        "        x_class = self.flatten(x_class)\n",
        "        x_class = torch.relu(self.linear1(x_class))\n",
        "        x_class = torch.relu(self.linear2(x_class))\n",
        "        x_class = torch.relu(self.linear3(x_class))\n",
        "        x_class = self.linear4(x_class)\n",
        "        return logits, x_class\n",
        "\n",
        "    def use_checkpointing(self):\n",
        "        self.inc = torch.utils.checkpoint(self.inc)\n",
        "        self.down1 = torch.utils.checkpoint(self.down1)\n",
        "        self.down2 = torch.utils.checkpoint(self.down2)\n",
        "        self.down3 = torch.utils.checkpoint(self.down3)\n",
        "        self.down4 = torch.utils.checkpoint(self.down4)\n",
        "        self.up1 = torch.utils.checkpoint(self.up1)\n",
        "        self.up2 = torch.utils.checkpoint(self.up2)\n",
        "        self.up3 = torch.utils.checkpoint(self.up3)\n",
        "        self.up4 = torch.utils.checkpoint(self.up4)\n",
        "        self.outc = torch.utils.checkpoint(self.outc)"
      ],
      "metadata": {
        "id": "tjdNnlPXHbLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, X, y1, y2):\n",
        "        self.X = X\n",
        "        self.y1 = y1\n",
        "        self.y2 = y2\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y1[idx], self.y2[idx]"
      ],
      "metadata": {
        "id": "6MYaNIUwHoIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment deffinition"
      ],
      "metadata": {
        "id": "sxldIP2PH9-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "-L_vJ3UiIEvD"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FY9XURmIG8vS",
        "outputId": "2634cb40-33f3-4ed5-c607-44f3b0576e3a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9AWG4ZTGYqo",
        "outputId": "46915c8a-820f-4164-cd93-a2a695d7fa8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
          ]
        }
      ],
      "source": [
        "model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet',\n",
        "    in_channels=3, out_channels=1, init_features=32, pretrained=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_k4OVIjGYqs",
        "outputId": "8a62ed13-9377-49f5-9002-caafc540cdf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UNet(\n",
            "  (inc): DoubleConv(\n",
            "    (double_conv): Sequential(\n",
            "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (down1): Down(\n",
            "    (maxpool_conv): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (1): DoubleConv(\n",
            "        (double_conv): Sequential(\n",
            "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (5): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (down2): Down(\n",
            "    (maxpool_conv): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (1): DoubleConv(\n",
            "        (double_conv): Sequential(\n",
            "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (5): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (down3): Down(\n",
            "    (maxpool_conv): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (1): DoubleConv(\n",
            "        (double_conv): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (5): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (down4): Down(\n",
            "    (maxpool_conv): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (1): DoubleConv(\n",
            "        (double_conv): Sequential(\n",
            "          (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (5): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (up1): Up(\n",
            "    (up): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
            "    (conv): DoubleConv(\n",
            "      (double_conv): Sequential(\n",
            "        (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (up2): Up(\n",
            "    (up): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "    (conv): DoubleConv(\n",
            "      (double_conv): Sequential(\n",
            "        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (up3): Up(\n",
            "    (up): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
            "    (conv): DoubleConv(\n",
            "      (double_conv): Sequential(\n",
            "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (up4): Up(\n",
            "    (up): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
            "    (conv): DoubleConv(\n",
            "      (double_conv): Sequential(\n",
            "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (outc): OutConv(\n",
            "    (conv): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (simoid): Sigmoid()\n",
            "  (conv1): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv2): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (max_pool): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear1): Linear(in_features=1152, out_features=256, bias=True)\n",
            "  (linear2): Linear(in_features=256, out_features=64, bias=True)\n",
            "  (linear3): Linear(in_features=64, out_features=16, bias=True)\n",
            "  (linear4): Linear(in_features=16, out_features=3, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "unet = UNet(3, 1).to(device)\n",
        "print(unet)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset deffinintion"
      ],
      "metadata": {
        "id": "eHVL0gfMIO4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "# Example usage:\n",
        "total_params = count_parameters(unet)\n",
        "print(\"Total trainable parameters: \", total_params)"
      ],
      "metadata": {
        "id": "ltL38pYxHjZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCHS = 50\n",
        "BATCH_SIZE = 16"
      ],
      "metadata": {
        "id": "QdfysL_OIKkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "xSrPdADyGYqt"
      },
      "outputs": [],
      "source": [
        "benign_images, benign_masks = read_data(directory = \"data//benign\", target_size=(256, 256))\n",
        "normal_images, normal_masks = read_data(directory = \"data//normal\", target_size=(256, 256))\n",
        "malignant_images, malignant_masks = read_data(directory = \"data//malignant\", target_size=(256, 256))\n",
        "\n",
        "benign_masks = np.reshape(benign_masks, (benign_masks.shape[0], 1, benign_masks.shape[1], benign_masks.shape[2]))\n",
        "normal_masks = np.reshape(normal_masks, (normal_masks.shape[0], 1, normal_masks.shape[1], normal_masks.shape[2]))\n",
        "malignant_masks = np.reshape(malignant_masks, (malignant_masks.shape[0], 1, malignant_masks.shape[1], malignant_masks.shape[2]))\n",
        "\n",
        "benign_images = np.transpose(benign_images, (0, 3, 1, 2))\n",
        "normal_images = np.transpose(normal_images, (0, 3, 1, 2))\n",
        "malignant_images = np.transpose(malignant_images, (0, 3, 1, 2))\n",
        "\n",
        "benign_values = np.array([1, 0, 0], dtype = np.float32)\n",
        "normal_values = np.array([0, 1, 0], dtype = np.float32)\n",
        "malignant_values = np.array([0, 0, 1], dtype = np.float32)\n",
        "num_benign = len(benign_images)\n",
        "num_normal = len(normal_images)\n",
        "num_malignant = len(malignant_images)\n",
        "y_classification = []\n",
        "y_segmentation = []\n",
        "X = []\n",
        "\n",
        "for i in range(num_benign):\n",
        "    y_classification.append(benign_values)\n",
        "for i in range(num_normal):\n",
        "    y_classification.append(normal_values)\n",
        "for i in range(num_malignant):\n",
        "    y_classification.append(malignant_values)\n",
        "y_classification = np.array(y_classification, dtype = np.float32)\n",
        "\n",
        "benign_masks[benign_masks>0] = 1\n",
        "normal_masks[normal_masks>0] = 1\n",
        "malignant_masks[malignant_masks>0] = 1\n",
        "benign_images = benign_images.astype(dtype = np.float32)\n",
        "normal_images = normal_images.astype(dtype = np.float32)\n",
        "malignant_images = malignant_images.astype(dtype = np.float32)\n",
        "benign_images /= 255\n",
        "normal_images /= 255\n",
        "malignant_images /= 255\n",
        "\n",
        "for img in benign_images:\n",
        "    X.append(img)\n",
        "for img in normal_images:\n",
        "    X.append(img)\n",
        "for img in malignant_images:\n",
        "    X.append(img)\n",
        "X = np.array(X, dtype=np.float32)\n",
        "\n",
        "for img in benign_masks:\n",
        "    y_segmentation.append(img)\n",
        "for img in normal_masks:\n",
        "    y_segmentation.append(img)\n",
        "for img in malignant_masks:\n",
        "    y_segmentation.append(img)\n",
        "y_segmentation = np.array(y_segmentation, dtype=np.float32)\n",
        "\n",
        "num_samples = len(y_segmentation)\n",
        "perm = np.random.permutation(num_samples)\n",
        "\n",
        "X = X[perm]\n",
        "y_classification = y_classification[perm]\n",
        "y_segmentation = y_segmentation[perm]\n",
        "\n",
        "total_samples = len(X)\n",
        "train_size = int(0.7 * total_samples)\n",
        "val_size = int(0.2 * total_samples)\n",
        "\n",
        "X_train = X[:train_size]\n",
        "y_classification_train = y_classification[:train_size]\n",
        "y_segmentation_train = y_segmentation[:train_size]\n",
        "\n",
        "X_val = X[train_size:train_size + val_size]\n",
        "y_classification_val = y_classification[train_size:train_size + val_size]\n",
        "y_segmentation_val = y_segmentation[train_size:train_size + val_size]\n",
        "\n",
        "X_test = X[train_size + val_size:]\n",
        "y_classification_test = y_classification[train_size + val_size:]\n",
        "y_segmentation_test = y_segmentation[train_size + val_size:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "KuYuE7U4GYqu"
      },
      "outputs": [],
      "source": [
        "X_train = torch.Tensor(X_train).to(device)\n",
        "y_classification_train = torch.Tensor(y_classification_train).to(device)\n",
        "y_segmentation_train = torch.Tensor(y_segmentation_train).to(device)\n",
        "\n",
        "X_val = torch.Tensor(X_val).to(device)\n",
        "y_classification_val = torch.Tensor(y_classification_val).to(device)\n",
        "y_segmentation_val = torch.Tensor(y_segmentation_val).to(device)\n",
        "\n",
        "X_test = torch.Tensor(X_test).to(device)\n",
        "y_classification_test = torch.Tensor(y_classification_test).to(device)\n",
        "y_segmentation_test = torch.Tensor(y_segmentation_test).to(device)\n",
        "\n",
        "train_dataset = CustomDataset(X_train, y_classification_train, y_segmentation_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "val_dataset = CustomDataset(X_val, y_classification_val, y_segmentation_val)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_dataset = CustomDataset(X_test, y_classification_test, y_segmentation_test)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qN1rnrayGYqu",
        "outputId": "219c3f62-4f72-4e9a-dd1d-b823303674d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(780, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "y_segmentation_train.shape\n",
        "y_classification.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "HZXuTVz4IW7r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhAUvreQGYqv",
        "outputId": "a2b55487-2237-4209-9c3a-2f3e078af0f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Classification Training Loss: 0.955375131538936, Train accuracy: 0.5928571428571429, Segmentation Training Loss: 1.0016214302607944, Classification Validation Loss: 1.0917680382728576, Segmentation Validation Loss: 0.8839552521705627, Classification Test Loss: 1.0915647506713868, Segmentation Test Loss: 0.8795144557952881\n",
            "Epoch: 1, Classification Training Loss: 0.9218259419713701, Train accuracy: 0.5821428571428572, Segmentation Training Loss: 0.9861087475504194, Classification Validation Loss: 5.3891083836555485, Segmentation Validation Loss: 0.8710388660430908, Classification Test Loss: 5.0572723865509035, Segmentation Test Loss: 0.8652086019515991\n",
            "Epoch: 2, Classification Training Loss: 0.9030047501836505, Train accuracy: 0.5928571428571429, Segmentation Training Loss: 0.9825591547148568, Classification Validation Loss: 2.578751450777054, Segmentation Validation Loss: 0.837088942527771, Classification Test Loss: 1.7458074688911438, Segmentation Test Loss: 0.8321650743484497\n",
            "Epoch: 3, Classification Training Loss: 0.8769324762480599, Train accuracy: 0.6607142857142857, Segmentation Training Loss: 0.9800914883613586, Classification Validation Loss: 19.98171411752701, Segmentation Validation Loss: 0.8498858153820038, Classification Test Loss: 15.114141654968261, Segmentation Test Loss: 0.845827865600586\n",
            "Epoch: 4, Classification Training Loss: 0.8889604840959822, Train accuracy: 0.6535714285714286, Segmentation Training Loss: 0.978338623046875, Classification Validation Loss: 14.402570152282715, Segmentation Validation Loss: 0.8300123453140259, Classification Test Loss: 10.145828127861023, Segmentation Test Loss: 0.8263661742210389\n",
            "Epoch: 5, Classification Training Loss: 0.8716567243848529, Train accuracy: 0.6678571428571428, Segmentation Training Loss: 0.9765213217054095, Classification Validation Loss: 32.77009000778198, Segmentation Validation Loss: 0.8184698522090912, Classification Test Loss: 27.124850845336915, Segmentation Test Loss: 0.814255702495575\n",
            "Epoch: 6, Classification Training Loss: 0.8550266810825893, Train accuracy: 0.6910714285714286, Segmentation Training Loss: 0.9748887436730521, Classification Validation Loss: 15.923463773727416, Segmentation Validation Loss: 0.8131305515766144, Classification Test Loss: 12.96737880706787, Segmentation Test Loss: 0.8091558694839478\n",
            "Epoch: 7, Classification Training Loss: 0.8418487020901271, Train accuracy: 0.7071428571428572, Segmentation Training Loss: 0.9731519341468811, Classification Validation Loss: 15.322269487380982, Segmentation Validation Loss: 0.8186177670955658, Classification Test Loss: 10.290946292877198, Segmentation Test Loss: 0.8149883031845093\n",
            "Epoch: 8, Classification Training Loss: 0.8384278093065535, Train accuracy: 0.7125, Segmentation Training Loss: 0.9715282763753619, Classification Validation Loss: 11.584037923812867, Segmentation Validation Loss: 0.8125831663608551, Classification Test Loss: 8.07940320968628, Segmentation Test Loss: 0.8091482162475586\n",
            "Epoch: 9, Classification Training Loss: 0.8373411740575518, Train accuracy: 0.7089285714285715, Segmentation Training Loss: 0.9701621566499983, Classification Validation Loss: 15.967434883117676, Segmentation Validation Loss: 0.806777149438858, Classification Test Loss: 10.302926826477051, Segmentation Test Loss: 0.8028533339500428\n",
            "Epoch: 10, Classification Training Loss: 0.8049826570919582, Train accuracy: 0.7517857142857143, Segmentation Training Loss: 0.9686208486557006, Classification Validation Loss: 14.911888682842255, Segmentation Validation Loss: 0.7955986797809601, Classification Test Loss: 11.383616161346435, Segmentation Test Loss: 0.7916069626808167\n",
            "Epoch: 11, Classification Training Loss: 0.8241490074566432, Train accuracy: 0.7321428571428571, Segmentation Training Loss: 0.9672517810549055, Classification Validation Loss: 33.42882232666015, Segmentation Validation Loss: 0.7913766443729401, Classification Test Loss: 21.339276695251463, Segmentation Test Loss: 0.7876031637191773\n",
            "Epoch: 12, Classification Training Loss: 0.8329452838216509, Train accuracy: 0.7142857142857143, Segmentation Training Loss: 0.9660559739385333, Classification Validation Loss: 25.414070391654967, Segmentation Validation Loss: 0.7956179857254029, Classification Test Loss: 17.077514839172363, Segmentation Test Loss: 0.7916196942329407\n",
            "Epoch: 13, Classification Training Loss: 0.837683093547821, Train accuracy: 0.7017857142857142, Segmentation Training Loss: 0.96475225346429, Classification Validation Loss: 36.3069073677063, Segmentation Validation Loss: 0.7943792879581452, Classification Test Loss: 25.122875595092772, Segmentation Test Loss: 0.7909457564353943\n",
            "Epoch: 14, Classification Training Loss: 0.8209344370024545, Train accuracy: 0.7285714285714285, Segmentation Training Loss: 0.9634046639714923, Classification Validation Loss: 24.179819202423097, Segmentation Validation Loss: 0.7799972236156464, Classification Test Loss: 20.24172248840332, Segmentation Test Loss: 0.7764340877532959\n",
            "Epoch: 15, Classification Training Loss: 0.8337616290364946, Train accuracy: 0.7160714285714286, Segmentation Training Loss: 0.9622992941311428, Classification Validation Loss: 46.36711931228638, Segmentation Validation Loss: 0.7820274353027343, Classification Test Loss: 41.46144523620605, Segmentation Test Loss: 0.7821222424507142\n",
            "Epoch: 16, Classification Training Loss: 0.8949666670390538, Train accuracy: 0.6535714285714286, Segmentation Training Loss: 0.9615458914211819, Classification Validation Loss: 133.28445281982422, Segmentation Validation Loss: 0.7735127389431, Classification Test Loss: 148.9632141113281, Segmentation Test Loss: 0.7705686450004577\n",
            "Epoch: 17, Classification Training Loss: 0.898455662386758, Train accuracy: 0.6517857142857143, Segmentation Training Loss: 0.9612417697906495, Classification Validation Loss: 37.467924213409425, Segmentation Validation Loss: 0.7768245160579681, Classification Test Loss: 27.058661270141602, Segmentation Test Loss: 0.7737830758094788\n",
            "Epoch: 18, Classification Training Loss: 0.8988892487117223, Train accuracy: 0.6446428571428572, Segmentation Training Loss: 0.9597364357539586, Classification Validation Loss: 42.46633377075195, Segmentation Validation Loss: 0.7699254631996155, Classification Test Loss: 31.600119590759277, Segmentation Test Loss: 0.7666496276855469\n",
            "Epoch: 19, Classification Training Loss: 0.8882366452898298, Train accuracy: 0.6553571428571429, Segmentation Training Loss: 0.9585989918027605, Classification Validation Loss: 32.782362937927246, Segmentation Validation Loss: 0.7656484961509704, Classification Test Loss: 29.75882806777954, Segmentation Test Loss: 0.7633034825325012\n",
            "Epoch: 20, Classification Training Loss: 1.076550805568695, Train accuracy: 0.4732142857142857, Segmentation Training Loss: 0.9576946445873805, Classification Validation Loss: 231.82260665893554, Segmentation Validation Loss: 0.7631417632102966, Classification Test Loss: 221.37308044433593, Segmentation Test Loss: 0.760969591140747\n",
            "Epoch: 21, Classification Training Loss: 1.2401033793176923, Train accuracy: 0.30892857142857144, Segmentation Training Loss: 0.9568401881626674, Classification Validation Loss: 225.07807273864745, Segmentation Validation Loss: 0.7637446999549866, Classification Test Loss: 213.35918884277345, Segmentation Test Loss: 0.7599496364593505\n",
            "Epoch: 22, Classification Training Loss: 1.0828667027609689, Train accuracy: 0.46785714285714286, Segmentation Training Loss: 0.9563127602849688, Classification Validation Loss: 99.5430793762207, Segmentation Validation Loss: 0.7574677228927612, Classification Test Loss: 80.13687858581542, Segmentation Test Loss: 0.7547399759292602\n",
            "Epoch: 23, Classification Training Loss: 0.9841206567628044, Train accuracy: 0.5660714285714286, Segmentation Training Loss: 0.9554962192262922, Classification Validation Loss: 160.90776901245118, Segmentation Validation Loss: 0.7624769866466522, Classification Test Loss: 202.12415466308593, Segmentation Test Loss: 0.7600964784622193\n",
            "Epoch: 24, Classification Training Loss: 0.9779522129467555, Train accuracy: 0.5732142857142857, Segmentation Training Loss: 0.9546028409685408, Classification Validation Loss: 155.2583417892456, Segmentation Validation Loss: 0.7562295794487, Classification Test Loss: 140.4196350097656, Segmentation Test Loss: 0.7558173775672913\n",
            "Epoch: 25, Classification Training Loss: 0.9670538987432208, Train accuracy: 0.5839285714285715, Segmentation Training Loss: 0.9535743832588196, Classification Validation Loss: 433.04342498779295, Segmentation Validation Loss: 0.7496171712875366, Classification Test Loss: 505.17864990234375, Segmentation Test Loss: 0.7487980246543884\n",
            "Epoch: 26, Classification Training Loss: 0.9599562202181134, Train accuracy: 0.5910714285714286, Segmentation Training Loss: 0.9530778918947492, Classification Validation Loss: 214.39754638671874, Segmentation Validation Loss: 0.7422179400920867, Classification Test Loss: 260.86240844726564, Segmentation Test Loss: 0.7410914778709412\n",
            "Epoch: 27, Classification Training Loss: 0.9579245226723807, Train accuracy: 0.5928571428571429, Segmentation Training Loss: 0.9521300230707441, Classification Validation Loss: 169.65308513641358, Segmentation Validation Loss: 0.741971206665039, Classification Test Loss: 209.7009307861328, Segmentation Test Loss: 0.741019856929779\n",
            "Epoch: 28, Classification Training Loss: 0.9558428168296814, Train accuracy: 0.5946428571428571, Segmentation Training Loss: 0.9513329982757568, Classification Validation Loss: 240.43159294128418, Segmentation Validation Loss: 0.7372397303581237, Classification Test Loss: 294.47320251464845, Segmentation Test Loss: 0.7359505295753479\n",
            "Epoch: 29, Classification Training Loss: 0.9546048556055341, Train accuracy: 0.5964285714285714, Segmentation Training Loss: 0.9506239260946001, Classification Validation Loss: 233.5034324645996, Segmentation Validation Loss: 0.7354410588741302, Classification Test Loss: 286.1531188964844, Segmentation Test Loss: 0.7343271374702454\n",
            "Epoch: 30, Classification Training Loss: 0.9543187294687544, Train accuracy: 0.5946428571428571, Segmentation Training Loss: 0.9499206100191389, Classification Validation Loss: 221.86961612701415, Segmentation Validation Loss: 0.7328370988368988, Classification Test Loss: 270.9123199462891, Segmentation Test Loss: 0.7319990515708923\n",
            "Epoch: 31, Classification Training Loss: 0.9533939123153686, Train accuracy: 0.5964285714285714, Segmentation Training Loss: 0.9492587055478777, Classification Validation Loss: 247.27370071411133, Segmentation Validation Loss: 0.730591744184494, Classification Test Loss: 301.2146423339844, Segmentation Test Loss: 0.7295296311378479\n",
            "Epoch: 32, Classification Training Loss: 0.9508602959769112, Train accuracy: 0.5982142857142857, Segmentation Training Loss: 0.9486670068332127, Classification Validation Loss: 233.74269943237306, Segmentation Validation Loss: 0.7282951593399047, Classification Test Loss: 284.8934020996094, Segmentation Test Loss: 0.727464246749878\n",
            "Epoch: 33, Classification Training Loss: 0.9501348955290658, Train accuracy: 0.5982142857142857, Segmentation Training Loss: 0.9482162186077663, Classification Validation Loss: 238.11573600769043, Segmentation Validation Loss: 0.7283505022525787, Classification Test Loss: 290.1368377685547, Segmentation Test Loss: 0.7272446751594543\n",
            "Epoch: 34, Classification Training Loss: 0.9487689426967076, Train accuracy: 0.6, Segmentation Training Loss: 0.9476426465170724, Classification Validation Loss: 255.45003280639648, Segmentation Validation Loss: 0.72525475025177, Classification Test Loss: 310.8672241210937, Segmentation Test Loss: 0.7246828436851501\n",
            "Epoch: 35, Classification Training Loss: 0.9485687732696533, Train accuracy: 0.6017857142857143, Segmentation Training Loss: 0.9471230779375349, Classification Validation Loss: 247.334468460083, Segmentation Validation Loss: 0.7225710988044739, Classification Test Loss: 300.86505432128905, Segmentation Test Loss: 0.7219527125358581\n",
            "Epoch: 36, Classification Training Loss: 0.9470965998513358, Train accuracy: 0.6017857142857143, Segmentation Training Loss: 0.9466514025415693, Classification Validation Loss: 235.35509452819824, Segmentation Validation Loss: 0.7224553823471069, Classification Test Loss: 285.9134063720703, Segmentation Test Loss: 0.7217537760734558\n",
            "Epoch: 37, Classification Training Loss: 0.9511013286454337, Train accuracy: 0.5964285714285714, Segmentation Training Loss: 0.9462102447237287, Classification Validation Loss: 263.71648559570315, Segmentation Validation Loss: 0.7208316266536713, Classification Test Loss: 319.66563110351564, Segmentation Test Loss: 0.7202641129493713\n",
            "Epoch: 38, Classification Training Loss: 0.9491281509399414, Train accuracy: 0.5982142857142857, Segmentation Training Loss: 0.9458066548619951, Classification Validation Loss: 260.59336166381837, Segmentation Validation Loss: 0.7192642092704773, Classification Test Loss: 316.27236022949216, Segmentation Test Loss: 0.7188886046409607\n",
            "Epoch: 39, Classification Training Loss: 0.9482958946909223, Train accuracy: 0.6017857142857143, Segmentation Training Loss: 0.9453968371663775, Classification Validation Loss: 241.0019145965576, Segmentation Validation Loss: 0.7195800423622132, Classification Test Loss: 292.7128021240234, Segmentation Test Loss: 0.7184996366500854\n",
            "Epoch: 40, Classification Training Loss: 0.9468747564724513, Train accuracy: 0.6035714285714285, Segmentation Training Loss: 0.945005874974387, Classification Validation Loss: 271.059432220459, Segmentation Validation Loss: 0.7204526245594025, Classification Test Loss: 328.9208099365234, Segmentation Test Loss: 0.7190728187561035\n",
            "Epoch: 41, Classification Training Loss: 0.9460756659507752, Train accuracy: 0.6035714285714285, Segmentation Training Loss: 0.9447377749851772, Classification Validation Loss: 263.2191566467285, Segmentation Validation Loss: 0.7159958600997924, Classification Test Loss: 319.3178680419922, Segmentation Test Loss: 0.7155587434768677\n",
            "Epoch: 42, Classification Training Loss: 0.9446545788219997, Train accuracy: 0.6035714285714285, Segmentation Training Loss: 0.9443529946463448, Classification Validation Loss: 268.93318328857424, Segmentation Validation Loss: 0.7141750037670136, Classification Test Loss: 326.1201690673828, Segmentation Test Loss: 0.7135738372802735\n",
            "Epoch: 43, Classification Training Loss: 0.9462003554616656, Train accuracy: 0.6035714285714285, Segmentation Training Loss: 0.9440446019172668, Classification Validation Loss: 272.49156646728517, Segmentation Validation Loss: 0.7137774348258972, Classification Test Loss: 329.792041015625, Segmentation Test Loss: 0.7130193591117859\n",
            "Epoch: 44, Classification Training Loss: 0.9449363129479544, Train accuracy: 0.6017857142857143, Segmentation Training Loss: 0.9437328457832337, Classification Validation Loss: 269.5253318786621, Segmentation Validation Loss: 0.7126778483390808, Classification Test Loss: 326.48012084960936, Segmentation Test Loss: 0.7122201323509216\n",
            "Epoch: 45, Classification Training Loss: 0.944237220287323, Train accuracy: 0.6053571428571428, Segmentation Training Loss: 0.9434301904269627, Classification Validation Loss: 260.68706970214845, Segmentation Validation Loss: 0.7116421163082123, Classification Test Loss: 317.54791870117185, Segmentation Test Loss: 0.7109947443008423\n",
            "Epoch: 46, Classification Training Loss: 0.946040301663535, Train accuracy: 0.6017857142857143, Segmentation Training Loss: 0.943132187638964, Classification Validation Loss: 264.52677764892576, Segmentation Validation Loss: 0.7115308582782746, Classification Test Loss: 322.42685852050784, Segmentation Test Loss: 0.71098872423172\n",
            "Epoch: 47, Classification Training Loss: 0.9445418289729527, Train accuracy: 0.6035714285714285, Segmentation Training Loss: 0.942894434928894, Classification Validation Loss: 300.1798690795898, Segmentation Validation Loss: 0.7102217257022858, Classification Test Loss: 367.2423919677734, Segmentation Test Loss: 0.7098001956939697\n",
            "Epoch: 48, Classification Training Loss: 0.9431851591382708, Train accuracy: 0.6053571428571428, Segmentation Training Loss: 0.9427807893071856, Classification Validation Loss: 272.77531776428225, Segmentation Validation Loss: 0.7095884025096894, Classification Test Loss: 333.85777587890624, Segmentation Test Loss: 0.7084299802780152\n",
            "Epoch: 49, Classification Training Loss: 0.9422469598906381, Train accuracy: 0.6053571428571428, Segmentation Training Loss: 0.9424439787864685, Classification Validation Loss: 276.2834899902344, Segmentation Validation Loss: 0.7093663811683655, Classification Test Loss: 337.92591552734376, Segmentation Test Loss: 0.708743441104889\n"
          ]
        }
      ],
      "source": [
        "unet = UNet(3, 1).to(device)\n",
        "unet.train()\n",
        "\n",
        "optimizer = Adam(unet.parameters(), lr = 1e-4)\n",
        "segmentation_loss = torch.nn.BCEWithLogitsLoss()\n",
        "classification_loss = nn.CrossEntropyLoss()\n",
        "\n",
        "classification_loss_train = []\n",
        "segmentation_loss_train = []\n",
        "classification_loss_val = []\n",
        "segmentation_loss_val = []\n",
        "classification_loss_test = []\n",
        "segmentation_loss_test = []\n",
        "accuracy_list = []\n",
        "\n",
        "for i in range(NUM_EPOCHS):\n",
        "    unet.train()\n",
        "    train_loss_class = []\n",
        "    train_loss_seg = []\n",
        "    val_loss_class = []\n",
        "    val_loss_seg = []\n",
        "    test_loss_class = []\n",
        "    test_loss_seg = []\n",
        "    accuracy = []\n",
        "\n",
        "    for batch in train_loader:\n",
        "        X_data, y_class, y_seg = batch\n",
        "        optimizer.zero_grad()\n",
        "        segmentation_output, classification_output = unet(X_data)\n",
        "        segmentation_output = torch.sigmoid(segmentation_output)\n",
        "        classification_output = torch.softmax(classification_output, dim=1)\n",
        "        seg_loss = segmentation_loss(segmentation_output, y_seg)\n",
        "        class_loss = classification_loss(classification_output, y_class)\n",
        "        loss = seg_loss + class_loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss_class.append(class_loss.item())\n",
        "        train_loss_seg.append(seg_loss.item())\n",
        "        predicted_classes = torch.argmax(classification_output, dim=1)\n",
        "        temp_class = torch.argmax(y_class, dim=1)\n",
        "        accuracy.append((predicted_classes == temp_class).float().mean().item())\n",
        "\n",
        "    accuracy = sum(accuracy)/len(accuracy)\n",
        "    accuracy_list.append(accuracy)\n",
        "    classification_loss_train.append(sum(train_loss_class) / len(train_loss_class))\n",
        "    segmentation_loss_train.append(sum(train_loss_seg) / len(train_loss_seg))\n",
        "\n",
        "    unet.eval()\n",
        "    with torch.no_grad():\n",
        "        val_loss_class = []\n",
        "        val_loss_seg = []\n",
        "        for batch in val_loader:\n",
        "            X_val, y_class_val, y_seg_val = batch\n",
        "            segmentation_output_val, classification_output_val = unet(X_val)\n",
        "            segmentation_output = torch.sigmoid(segmentation_output)\n",
        "            classification_output = torch.softmax(classification_output, dim=1)\n",
        "            seg_loss_val = segmentation_loss(segmentation_output_val, y_seg_val)\n",
        "            class_loss_val = classification_loss(classification_output_val, y_class_val)\n",
        "            val_loss_class.append(class_loss_val.item())\n",
        "            val_loss_seg.append(seg_loss_val.item())\n",
        "\n",
        "        classification_loss_val.append(sum(val_loss_class) / len(val_loss_class))\n",
        "        segmentation_loss_val.append(sum(val_loss_seg) / len(val_loss_seg))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        test_loss_class = []\n",
        "        test_loss_seg = []\n",
        "        for batch in test_loader:\n",
        "            X_test, y_class_test, y_seg_test = batch\n",
        "            segmentation_output_test, classification_output_test = unet(X_test)\n",
        "            segmentation_output = torch.sigmoid(segmentation_output)\n",
        "            classification_output = torch.softmax(classification_output, dim=1)\n",
        "            seg_loss_test = segmentation_loss(segmentation_output_test, y_seg_test)\n",
        "            class_loss_test = classification_loss(classification_output_test, y_class_test)\n",
        "            test_loss_class.append(class_loss_test.item())\n",
        "            test_loss_seg.append(seg_loss_test.item())\n",
        "\n",
        "        classification_loss_test.append(sum(test_loss_class) / len(test_loss_class))\n",
        "        segmentation_loss_test.append(sum(test_loss_seg) / len(test_loss_seg))\n",
        "\n",
        "    print(f\"Epoch: {i}, Classification Training Loss: {classification_loss_train[-1]}, Train accuracy: {accuracy_list[-1]}, Segmentation Training Loss: {segmentation_loss_train[-1]}, Classification Validation Loss: {classification_loss_val[-1]}, Segmentation Validation Loss: {segmentation_loss_val[-1]}, Classification Test Loss: {classification_loss_test[-1]}, Segmentation Test Loss: {segmentation_loss_test[-1]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model saving"
      ],
      "metadata": {
        "id": "n2F5jTuxIaxT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "LA8H7TJzGYqv"
      },
      "outputs": [],
      "source": [
        "torch.save(unet.state_dict(), 'ynet.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "3eNbfWaiGYqv"
      },
      "outputs": [],
      "source": [
        "lists_to_save = {\n",
        "    'classification_loss_train': classification_loss_train,\n",
        "    'segmentation_loss_train': segmentation_loss_train,\n",
        "    'classification_loss_val': classification_loss_val,\n",
        "    'segmentation_loss_val': segmentation_loss_val,\n",
        "    'classification_loss_test': classification_loss_test,\n",
        "    'segmentation_loss_test': segmentation_loss_test\n",
        "}\n",
        "\n",
        "with open('unet_results_1.pkl', 'wb') as f:\n",
        "    pickle.dump(lists_to_save, f)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}